{"cells":[{"cell_type":"markdown","id":"7bf94f9b","metadata":{"id":"7bf94f9b"},"source":["# Алгоритм Франк-Вульфа (20 баллов)"]},{"cell_type":"code","execution_count":3,"id":"47837c7b","metadata":{"id":"47837c7b","executionInfo":{"status":"ok","timestamp":1763401647670,"user_tz":-180,"elapsed":40,"user":{"displayName":"Yaroslav Andreev","userId":"08176149003175858385"}}},"outputs":[],"source":["import numpy as np\n","import math\n","import itertools\n","from matplotlib import pyplot as plt\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"00acc29c","metadata":{"id":"00acc29c"},"source":["Вспомним основные свойства логистической регрессии с кросс-энтропийной функцией потерь:\n","1. Модель:\n","\n","$$\n","g(x, a_i) = \\frac{1}{1 + \\exp \\left[- \\langle x, a_i \\rangle\\right]};\n","$$\n","\n","2. Функция потерь:\n","\n","$$\n","\\ell(g(x, a_i), b_i) = -b_i \\log \\left[g(x, a_i)\\right] - (1 - b_i) \\log \\left[1 -  g(x, a_i)\\right].\n","$$\n","\n","3. Полный вид оптимизационной задачи:\n","\n","$$\n","\\min_{x \\in \\mathbb{R}^d} \\left[ f(x) = \\frac{1}{n} \\sum_{i=1}^n \\ell \\left(g(x, a_i), b_i \\right) + \\frac{\\lambda}{2} \\| x \\|^2_2 \\right],\n","$$\n","\n","4. Градиент функции потерь:\n","\n","$$\n","\\nabla f(x) = \\frac{1}{n} \\sum_{i=1}^n (g(x, a_i) - b_i) a_i + \\lambda x.\n","$$\n","   \n","5. Константа $L$-гладкости оценивается как\n","\n","$$\n","L \\geq \\frac{1}{4n} \\lambda_{\\max} \\left[A^\\top A \\right] + \\lambda,\n","$$\n","\n","6. Константа $\\mu$-сильной выпуклости оценивается как $\\mu \\leq \\lambda$."]},{"cell_type":"markdown","id":"2a85e426","metadata":{"id":"2a85e426"},"source":["В качестве дата-матрицы $A$ и целевого вектора $b$ рассмотрим данные из датасета [_mushrooms_](https://github.com/BRAIn-Lab-teaching/OPTIMIZATION-METHODS-COURSE/blob/ПМИ_осень_2025/Datasets/mushrooms.txt). Ниже представлена функция загрузки датасета."]},{"cell_type":"code","source":["url = \"https://raw.githubusercontent.com/BRAIn-Lab-teaching/OPTIMIZATION-METHODS-COURSE/%D0%9F%D0%9C%D0%98_%D0%BE%D1%81%D0%B5%D0%BD%D1%8C_2025/Datasets/mushrooms.txt\"\n","!wget -O mushrooms.txt \"$url\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MphCS8R7Zdo","executionInfo":{"status":"ok","timestamp":1763401647952,"user_tz":-180,"elapsed":269,"user":{"displayName":"Yaroslav Andreev","userId":"08176149003175858385"}},"outputId":"3d3e8b74-88ac-4385-b019-222e830473b2"},"id":"8MphCS8R7Zdo","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-11-17 17:47:27--  https://raw.githubusercontent.com/BRAIn-Lab-teaching/OPTIMIZATION-METHODS-COURSE/%D0%9F%D0%9C%D0%98_%D0%BE%D1%81%D0%B5%D0%BD%D1%8C_2025/Datasets/mushrooms.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 879712 (859K) [text/plain]\n","Saving to: ‘mushrooms.txt’\n","\n","\rmushrooms.txt         0%[                    ]       0  --.-KB/s               \rmushrooms.txt       100%[===================>] 859.09K  --.-KB/s    in 0.03s   \n","\n","2025-11-17 17:47:27 (25.8 MB/s) - ‘mushrooms.txt’ saved [879712/879712]\n","\n"]}]},{"cell_type":"code","execution_count":5,"id":"a710be56","metadata":{"id":"a710be56","executionInfo":{"status":"ok","timestamp":1763401648072,"user_tz":-180,"elapsed":118,"user":{"displayName":"Yaroslav Andreev","userId":"08176149003175858385"}}},"outputs":[],"source":["from sklearn.datasets import load_svmlight_file\n","\n","#файл должен лежать в той же директории, что и notebook\n","dataset = \"mushrooms.txt\"\n","\n","data = load_svmlight_file(dataset)\n","A, b = data[0].toarray(), data[1]\n","\n","# Необходимое линейное преобразование\n","b = b - 1"]},{"cell_type":"markdown","id":"2230022e","metadata":{"id":"2230022e"},"source":["С помощью функции `train_test_split` разделите датасет в отношении 4 к 1 (обучающая выборка должна быть в 4 раза больше, чем тестовая). Поставьте параметр `random_state = 57`. В дальнейшем мы будем валидировать процесс обучения на тестовой выборке."]},{"cell_type":"code","execution_count":6,"id":"a8a63a80","metadata":{"id":"a8a63a80","executionInfo":{"status":"ok","timestamp":1763401648351,"user_tz":-180,"elapsed":277,"user":{"displayName":"Yaroslav Andreev","userId":"08176149003175858385"}}},"outputs":[],"source":["import sklearn\n","A_train, A_test, b_train, b_test = sklearn.model_selection.train_test_split(A, b, test_size=0.2, random_state = 57)"]},{"cell_type":"markdown","id":"acab6a19","metadata":{"id":"acab6a19"},"source":["Для обучающей части $A_{train}$, $b_{train}$ оцените константы $L$ и $\\mu$, положив равенство в полученной ранее оценке. Задайте $\\lambda$ так, чтобы $\\lambda \\approx L / 1000$."]},{"cell_type":"code","execution_count":7,"id":"2822e2d9","metadata":{"id":"2822e2d9","executionInfo":{"status":"ok","timestamp":1763401648365,"user_tz":-180,"elapsed":33,"user":{"displayName":"Yaroslav Andreev","userId":"08176149003175858385"}}},"outputs":[],"source":["eigvals = np.linalg.eigvalsh(A_train.T.dot(A_train))\n","lambda_max = np.max(eigvals)\n","n_train = A_train.shape[0]\n","L = eigvals.max() / (4 * n_train)\n","mu = L / 1000\n","lambda_value = mu\n","\n","\n","assert math.isclose(L, 2.586914976545057,  rel_tol=1e-6),  \"Константа L-гладкости найдена неверно\"\n","assert math.isclose(mu, 0.002586914976545057, rel_tol=1e-6),  \"Константа регуляризации найдена неверно\""]},{"cell_type":"markdown","id":"344f098c","metadata":{"ExecuteTime":{"end_time":"2025-10-29T22:36:44.027309Z","start_time":"2025-10-29T22:36:44.019555Z"},"id":"344f098c"},"source":["Дополните функции подсчета сигмоиды, кросс-энтропии и градиента оптимизируемой функции."]},{"cell_type":"code","execution_count":8,"id":"19c1bd28","metadata":{"id":"19c1bd28","executionInfo":{"status":"ok","timestamp":1763401648378,"user_tz":-180,"elapsed":12,"user":{"displayName":"Yaroslav Andreev","userId":"08176149003175858385"}}},"outputs":[],"source":["def sigmoid(x):\n","    \"\"\"\n","    Вычисляет сигмоидную функцию.\n","\n","    Параметры:\n","        x (np.array): Входное значение\n","\n","    Возвращает:\n","        sigmoid (np.array) Значение сигмоидной функции для входных данных\n","    \"\"\"\n","    \"\"\"\n","    Было предупреждение о переполнении экспоненты, пришлось придумывать костыли, чтобы не было переполнения\n","    \"\"\"\n","\n","    pos_mask = (x >= 0)\n","    neg_mask = (x < 0)\n","\n","    z = np.zeros_like(x)\n","    z[pos_mask] = np.exp(-x[pos_mask])\n","    z[neg_mask] = np.exp(x[neg_mask])\n","\n","    result = np.zeros_like(x)\n","    result[pos_mask] = 1 / (1 + z[pos_mask])\n","    result[neg_mask] = z[neg_mask] / (1 + z[neg_mask])\n","\n","    return result\n","\n","\n","def loss(x, A=A_train, b=b_train, lambda_value=L/1000):\n","    \"\"\"\n","    Вычисляет значение эмпирического риска.\n","\n","    Параметры:\n","        x (np.array): Вектор параметров модели\n","        A (np.array): Матрица признаков обучающей выборки\n","        b (np.array): Вектор меток обучающей выборки\n","        lambda_value (float): Параметр регуляризации\n","\n","    Возвращает:\n","        loss (float): Значение функции потерь\n","    \"\"\"\n","\n","    epsilon = 1e-10\n","\n","    g_value = sigmoid(A @ x)\n","\n","    g_value = np.clip(g_value, epsilon, 1 - epsilon)\n","\n","    cross_entropy_loss = -np.mean(b * np.log(g_value) + (1 - b) * np.log(1 - g_value))\n","\n","    regularization = (lambda_value / 2) * np.sum(x**2)\n","\n","    loss = cross_entropy_loss + regularization\n","\n","    return loss\n","\n","\n","\n","def grad(x, A=A_train, b=b_train, lambda_value=L/1000):\n","    \"\"\"\n","    Вычисляет градиент функции потерь.\n","\n","    Параметры:\n","        x (np.array): Вектор параметров модели\n","        A (np.array): Матрица признаков обучающей выборки\n","        b (np.array): Вектор меток обучающей выборки\n","        lambda_value (float): Параметр регуляризации\n","\n","    Возвращает:\n","        grad (np.array): Градиент функции потерь\n","    \"\"\"\n","\n","    predictions = sigmoid(A @ x)\n","\n","    grad = (A.T @ (predictions - b)) / len(b) + lambda_value * x\n","\n","    return grad\n",""]},{"cell_type":"markdown","id":"7bae7d90","metadata":{"id":"7bae7d90"},"source":["## Основная часть (10 баллов)"]},{"cell_type":"markdown","id":"91491dab","metadata":{"id":"91491dab"},"source":["__Задача 1.__ В методе Франк-Вульфа мы не используем проекции на множество, а отрешиваем подзадачу для выполнения шага алгоритма. Данная подзадача называется __LMO (Linear Minimization Oracle)__, и для некоторого вектора $c$ и выпуклого замкнутого множества $\\mathcal{X}$ принимает вид:\n","\n","$$\n","\\text{LMO}(c) = \\arg \\min_{s \\in \\mathcal{X}} \\langle c, s \\rangle.\n","$$"]},{"cell_type":"markdown","id":"77487834","metadata":{"id":"77487834"},"source":["__а) (1 балл)__ Покажите, что для симплекса:\n","\n","$$\n","\\mathcal{X} = \\left\\{ s \\in \\mathbb{R}^d \\mid s \\succeq 0,~ \\boldsymbol{1}^\\top s = R \\right\\}\n","$$\n","\n","решение LMO:\n","\n","$$\n","s^* = R e_i,~ \\text{где}~ i = \\arg \\min_{j = \\overline{1, d}} c_j.\n","$$"]},{"cell_type":"markdown","id":"e9246937","metadata":{"id":"e9246937"},"source":["Реализуйте `lmo_simplex`."]},{"cell_type":"code","execution_count":9,"id":"b2ac849d","metadata":{"id":"b2ac849d","executionInfo":{"status":"ok","timestamp":1763401648410,"user_tz":-180,"elapsed":30,"user":{"displayName":"Yaroslav Andreev","userId":"08176149003175858385"}}},"outputs":[],"source":["def lmo_simplex(g, R):\n","    \"\"\"\n","    LMO для симплекса.\n","\n","    Параметры:\n","        g (np.array): Градиент в текущей точке\n","        R (float): Размер симплекса\n","\n","    Возвращает:\n","        s (np.array): LMO\n","    \"\"\"\n","\n","    i = int(np.argmin(g))\n","    s = np.zeros_like(g, dtype=float)\n","    s[i] = float(R)\n","    return s"]},{"cell_type":"markdown","id":"e00b5cc0","metadata":{"id":"e00b5cc0"},"source":["__б) (1 балл)__ Покажите, что для $\\ell_1$-шара:\n","\n","$$\n","\\mathcal{X} = \\left\\{ s \\in \\mathbb{R}^d \\mid \\|s\\|_1 \\leq R \\right\\}\n","$$\n","\n","решение LMO:\n","\n","$$\n","s^* = -R \\text{sign}(c_i) e_i,~ \\text{где}~ i = \\arg \\max_{j = \\overline{1, d}} |c_j|.\n","$$"]},{"cell_type":"markdown","id":"732ac72b","metadata":{"id":"732ac72b"},"source":["Реализуйте `lmo_l1_ball`."]},{"cell_type":"code","execution_count":10,"id":"3afd763b","metadata":{"id":"3afd763b","executionInfo":{"status":"ok","timestamp":1763401648412,"user_tz":-180,"elapsed":4,"user":{"displayName":"Yaroslav Andreev","userId":"08176149003175858385"}}},"outputs":[],"source":["def lmo_l1_ball(g, R):\n","    \"\"\"\n","    LMO для L1-шара.\n","\n","    Параметры:\n","        g (np.array): Градиент в текущей точке\n","        R (float): Размер симплекса\n","\n","    Возвращает:\n","        s (np.array): LMO\n","    \"\"\"\n","\n","    i = int(np.argmax(np.abs(g)))\n","\n","    s = np.zeros_like(g, dtype=float)\n","    s[i] = -R * np.sign(g[i])\n","\n","    return s"]},{"cell_type":"markdown","id":"6e3f02cc","metadata":{"id":"6e3f02cc"},"source":["__в) (2 балла)__ Реализуйте алгоритм Франк-Вульфа. На каждой итерации сохраняйте:\n","\n","- Значение функции потерь;\n","- Норму градиента;\n","- Значение метрики\n","\n","$$\n","\\text{gap}(x^k) = \\langle \\nabla f(x^k), x^k - s^k \\rangle;\n","$$\n","\n","- Усредненное значение метрики $\\text{gap}(x^k)$:\n","\n","$$\n","\\text{gap} = \\frac{1}{k} \\sum_{t = 0}^k \\text{gap}(x^t).\n","$$\n","\n","**Псевдокод алгоритма**\n","\n","---\n","\n","_Инициализация:_\n","\n","- Размер шага $\\left\\{ \\gamma_k = \\frac{2}{k+2} \\right\\} _{k=0}$\n","- Начальная точка $ x^0 \\in \\mathbb{R}^d $\n","- Максимальное число итераций $K$\n","\n","---\n","\n","$k$_-ая итерация_:\n","   \n","1. Найти оптимальное направление:\n","\n","$$\n","s^k = \\arg \\min_{s \\in \\mathcal{X}} \\langle s, \\nabla f(x^k) \\rangle\n","$$\n","\n","2. Обновить значение:\n","\n","$$\n","x^{k + 1} = (1 - \\gamma_k) x^k + \\gamma_k s^k\n","$$\n","\n","---\n","\n","_Условие остановки:_\n","- Достигнуто максимальное число итераций $K$ или $\\text{gap} (x^k) < \\varepsilon$\n","\n","---\n","\n","_Выход:_\n","- Полученное значение $x^K$"]},{"cell_type":"code","execution_count":null,"id":"671dfd0c","metadata":{"id":"671dfd0c"},"outputs":[],"source":["def frank_wolfe(A, b, lambda_value, grad, lmo, x_0, eps=1e-8, max_iter=1000, **params):\n","    \"\"\"\n","    Алгоритм Франк-Вульфа.\n","\n","    Параметры:\n","        A (np.array): Матрица признаков.\n","        b (np.array): Вектор целевых значений\n","        lambda_value (float): Параметр регуляризации\n","        grad (Callable): Функция вычисления градиента\n","        lmo (Callable): Функция вычисления LMO\n","        x_0 (np.array): Начальная точка\n","        eps (float): Точность сходимости\n","        max_iter (int): Максимальное количество итераций\n","        params : Именованные гиперпараметры метода\n","            params['gamma'](k) : шаг на k-ой итерации\n","            params['R'] : радиус множества\n","\n","    Возвращает:\n","        x_k (np.array) : Найденное решение\n","        history (list) : История метрики и значения\n","    \"\"\"\n","    x_k = x_0.copy()\n","    history = {\n","        'values': [],\n","        'norms': [],\n","        'gaps': [],\n","        'gaps_averaged': [],\n","        'times': []\n","    }\n","    gaps_sum = 0.0\n","    start_time = time.time()\n","\n","    R = params['R']\n","\n","    for k in range(max_iter):\n","\n","        gamma = params['gamma'](k)\n","\n","        g_k = grad(x_k, A, b, lambda_value)\n","\n","        s_k = lmo(g_k, R)\n","\n","        x_k = (1 - gamma) * x_k + gamma * x_k\n","\n","        gap_k = np.dot(g_k, x_k - s_k)\n","\n","        gaps_sum += gap_k\n","\n","        # Сохранение истории\n","        history['values'].append(loss(x_k, A, b, lambda_value))\n","        history['norms'].append(np.linalg.norm(g_k))\n","        history['gaps'].append(gap_k)\n","        history['gaps_averaged'].append(gaps_sum / (k + 1))\n","        history['times'].append(time.time() - start_time)\n","\n","        if history['gaps'][-1] < eps:\n","            break\n","\n","    return x_k, history"]},{"cell_type":"markdown","id":"c5d9aa99","metadata":{"id":"c5d9aa99"},"source":["Запустите оптимизацию на обучающей подвыборке для обоих типов LMO. В качестве значения радиуса для $L_1$-шара примите $R = 5$, размера симплекса $R = 1$, cтартовую точку возьмите в $0$."]},{"cell_type":"code","execution_count":null,"id":"3bf13427","metadata":{"id":"3bf13427"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"31403107","metadata":{"id":"31403107"},"source":["Постройте сравнительный график сходимости: значение критерия сходимости $\\text{gap} (x^k)$ и $\\text{gap}$ от номера итерации."]},{"cell_type":"code","execution_count":null,"id":"d9c9069a","metadata":{"id":"d9c9069a"},"outputs":[],"source":["# Ваше решение (Code)"]},{"cell_type":"markdown","id":"0d0dbc13","metadata":{"id":"0d0dbc13"},"source":["__г) (1 балл)__ Проанализируйте вектор $x^K$, полученный на выходе. Для этого сделайте гистограмму значений полученного вектора, а также гистограмму разреженности (отношения количества ненулевых компонент к нулевым). Выведите также топ-5 компонент вектора $x^K$ по модулю."]},{"cell_type":"code","execution_count":null,"id":"2ab4fb0f","metadata":{"id":"2ab4fb0f"},"outputs":[],"source":["# Ваше решение (Code)"]},{"cell_type":"markdown","id":"7827b4aa","metadata":{"id":"7827b4aa"},"source":["Сделайте выводы."]},{"cell_type":"code","execution_count":null,"id":"59f71964","metadata":{"id":"59f71964"},"outputs":[],"source":["# Ваше решение (Markdown)"]},{"cell_type":"markdown","id":"65373c6b","metadata":{"id":"65373c6b"},"source":["__д) (2 балла)__ Исследуйте зависимость значения метрики `accuracy` модели от радиуса $R$ для LMO на $L_1$-шаре. Рассмотрите следующие значения: $R = 5, 10, 20, 50, 100, 1000$.\n","\n","Постройте 4 сравнительных графика:\n","\n","- `accuracy` итоговой модели от значения $R$ (train/test),\n","- `accuracy` итоговой модели от количества ненулевых компонент решения (train/test),\n","- Количество ненулевых компоненты решения от $R$,\n","- $L_1$-норма решения от $R$."]},{"cell_type":"code","execution_count":null,"id":"9e7e6883","metadata":{"id":"9e7e6883"},"outputs":[],"source":["# Ваше решение (Code)"]},{"cell_type":"markdown","id":"6a77e854","metadata":{"ExecuteTime":{"end_time":"2025-10-30T01:24:51.259831Z","start_time":"2025-10-30T01:24:51.247567Z"},"id":"6a77e854"},"source":["Проанализируйте зависимости, объясните полученные результаты."]},{"cell_type":"code","execution_count":null,"id":"ce3b3b6d","metadata":{"id":"ce3b3b6d"},"outputs":[],"source":["# Ваше решение (Markdown)"]},{"cell_type":"markdown","id":"64db33a9","metadata":{"id":"64db33a9"},"source":["__Задача 2.__ Сравним теперь метод Франк-Вульфа с градиентным спуском с проекцией."]},{"cell_type":"markdown","id":"e94c9ebc","metadata":{"id":"e94c9ebc"},"source":["__а) (1 балл)__ Покажите, что для $\\ell_1$-шара:\n","\n","$$\n","\\mathcal{X} = \\left\\{ y \\in \\mathbb{R}^d \\mid \\|y\\|_1 \\leq R \\right\\}\n","$$\n","\n","решение проекции:\n","\n","$$\n","\\Pi_{\\mathcal{X}}(x) =\n","\\begin{cases}\n","    x, & \\|s\\|_1 \\leq R, \\\\\n","    \\text{sign}(x_i)(|x_i| - \\lambda)_{+}~ \\forall i \\in \\overline{1, d}, & \\|s\\|_1 > R,\n","\\end{cases}\n","$$\n","\n","где $\\lambda$ определяется из уравнения\n","\n","$$\n","\\sum_{i = 1}^d (|x_i| - \\lambda)_{+} = R.\n","$$"]},{"cell_type":"code","execution_count":null,"id":"08293a58","metadata":{"id":"08293a58"},"outputs":[],"source":["# Ваше решение (Markdown)"]},{"cell_type":"markdown","id":"27cbfcb5","metadata":{"id":"27cbfcb5"},"source":["Реализуйте `project_l1_ball`."]},{"cell_type":"code","execution_count":null,"id":"9432cbb2","metadata":{"id":"9432cbb2"},"outputs":[],"source":["def project_l1_ball(x, R):\n","    \"\"\"\n","    Проекция вектора x на L1-шар радиуса R.\n","\n","    Параметры:\n","        x (np.array): Точка, из которой считается проекция\n","        R (float): Размер симплекса\n","\n","    Возвращает:\n","        y (np.array): Проекция\n","    \"\"\"\n","\n","    # YOUR CODE HERE\n","\n","    return y"]},{"cell_type":"markdown","id":"758fb696","metadata":{"id":"758fb696"},"source":["__б) (2 балла)__ Решите задачу оптимизации на обучающей выборке с помощью градиентного спуска с проекцией."]},{"cell_type":"code","execution_count":null,"id":"2047a7b6","metadata":{"id":"2047a7b6"},"outputs":[],"source":["def projected_gradient_descent(A, b, lambda_value, grad, proj, x_0, eps=1e-8, max_iter=1000, **params):\n","    \"\"\"\n","    Градиентный спуск с проекцией.\n","\n","    Параметры:\n","        A (np.array): Матрица признаков.\n","        b (np.array): Вектор целевых значений\n","        lambda_value (float): Параметр регуляризации\n","        grad (Callable): Функция вычисления градиента\n","        proj (Callable): Функция вычисления проекции\n","        x_0 (np.array): Начальная точка\n","        eps (float): Точность сходимости\n","        max_iter (int): Максимальное количество итераций\n","        params : Именованные гиперпараметры метода\n","            params['gamma'](k) : шаг на k-ой итерации\n","            params['R'] : радиус множества\n","\n","    Возвращает:\n","        x_k (np.array) : Найденное решение\n","        history (list) : История метрики и значения\n","    \"\"\"\n","    x_k = x_0.copy()\n","\n","    history = {\n","        'values': [],\n","        'norms': [],\n","        'times': []\n","    }\n","    start_time = time.time()\n","\n","    for k in range(max_iter):\n","\n","        # YOUR CODE HERE\n","\n","        # История\n","        history['values'].append(loss(x_k, A, b))\n","        history['norms'].append(np.linalg.norm(g_k))\n","        history['times'].append(time.time() - start_time)\n","\n","    return x_k, history"]},{"cell_type":"markdown","id":"94affca6","metadata":{"id":"94affca6"},"source":["Сравните градиентный спуск с проекцией и алгоритм Франк—Вульфа для $R = 5$."]},{"cell_type":"code","execution_count":null,"id":"644e7d43","metadata":{"id":"644e7d43"},"outputs":[],"source":["# Ваше решение (Code)"]},{"cell_type":"markdown","id":"7abb00ff","metadata":{"id":"7abb00ff"},"source":["Постройте 3 сравнительных графика:\n","- Значение функции от номера итерации,\n","- Значение функции от времени,\n","- Значение $L_2$ нормы от итерации."]},{"cell_type":"code","execution_count":null,"id":"dea04cc8","metadata":{"id":"dea04cc8"},"outputs":[],"source":["# Ваше решение (Code)"]},{"cell_type":"markdown","id":"b3d74df2","metadata":{"id":"b3d74df2"},"source":["Убедитесь в том, что метод Франка—Вульфа сходится быстрее, чем градиентный спуск с проекцией. Cравните число ненулевых компонент в итоговом решении."]},{"cell_type":"code","execution_count":null,"id":"91674d50","metadata":{"id":"91674d50"},"outputs":[],"source":["# Ваше решение (Code)"]},{"cell_type":"markdown","id":"7b9c5ced","metadata":{"id":"7b9c5ced"},"source":["## Дополнительная часть (10 баллов)"]},{"cell_type":"code","execution_count":null,"id":"9bd6ad65","metadata":{"id":"9bd6ad65"},"outputs":[],"source":["from tqdm import tqdm\n","import torch\n","from torch import optim\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.models import resnet18"]},{"cell_type":"markdown","id":"68bdb4e6","metadata":{"id":"68bdb4e6"},"source":["__Задача 3.__ В этой задаче вам будет предложено сначала найти $\\text{LMO}$ на ядерный шар заданого радиуса $R$. А затем реализовать алгоритм Франк—Вульфа для обучения нейронной сети. Такой оптимизатор является SOTA оптимизатором для пре-трейна Muon. Почитать про теоретическое обоснование можно [здесь](https://arxiv.org/pdf/2506.04192)."]},{"cell_type":"markdown","id":"6f791195","metadata":{"id":"6f791195"},"source":["__а) (3 балла)__ Ядерной нормой матрицы $X \\in \\mathbb{R}^{n \\times d}$ называется:\n","\n","$$\n","\\| X \\|_* = \\sum_{i = 1}^{\\min \\{n, d\\}} \\sigma_i,\n","$$\n","\n","где $\\sigma_i$ — сингулярные числа матрицы $X$. Покажите, что для ядерного шара:\n","\n","$$\n","\\mathcal{X} = \\left\\{ S \\in \\mathbb{R}^{n \\times d} \\mid \\| S \\|_* \\leq R \\right\\}.\n","$$\n","\n","решение LMO:\n","\n","$$\n","S^* = -R u_1 v_1^\\top,\n","$$\n","\n","где $u_1$, $v_1$ — левый и правый сингулярные векторы матрицы $C$ при максимальном сингулярном числе.\n","\n","_Указание: прочитайте про нормы Шаттена._"]},{"cell_type":"code","execution_count":null,"id":"6e525960","metadata":{"id":"6e525960"},"outputs":[],"source":["# Ваше решение (Markdown)"]},{"cell_type":"markdown","id":"4a215664","metadata":{"id":"4a215664"},"source":["__б) (1 балл)__  Допишите `LMO` для класса `NuclearNormBall`."]},{"cell_type":"code","execution_count":null,"id":"c165e75b","metadata":{"id":"c165e75b"},"outputs":[],"source":["class NuclearNormBall:\n","    \"\"\"\n","    Ограничения — ядерный шар.\n","    \"\"\"\n","    def __init__(self, l2_diameter):\n","        self._R = l2_diameter / 2\n","\n","    @torch.no_grad()\n","    def SVD_power_iteration(self, W, iterations=20):\n","        \"\"\"\n","        Power iteration для вычисления первых сингулярных векторов\n","        \"\"\"\n","        n, m = W.shape\n","        u = F.normalize(W.new_empty(n).normal_(0., 1.), dim=0)\n","        v = F.normalize(W.new_empty(m).normal_(0., 1.), dim=0)\n","        for _ in range(iterations):\n","            v = F.normalize(torch.mv(W.t(), u), dim=0)\n","            u = F.normalize(torch.mv(W, v), dim=0)\n","        sigma = torch.dot(u, torch.mv(W, v))\n","        return u, sigma, v\n","\n","    @torch.no_grad()\n","    def lmo(self, x):\n","        \"\"\"\n","        LMO.\n","\n","        Параметры:\n","            x (torch.Tensor): Градиент в текущей точке\n","\n","        Возвращает:\n","            lmo_solution (torch.Tensor): LMO\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","\n","        return lmo_solution\n","\n","    @torch.no_grad()\n","    def shift_inside(self, x):\n","        \"\"\"\n","        Масштабирование.\n","        \"\"\"\n","        u, sigma, v = self.SVD_power_iteration(x.flatten(1))\n","        nuclear_norm_val = sigma.sum()\n","        if nuclear_norm_val > self._R:\n","            sigma_new = torch.diag(sigma * (self._R / nuclear_norm_val))\n","            return u @ sigma_new @ v\n","        else:\n","            return x"]},{"cell_type":"markdown","id":"a4de0993","metadata":{"id":"a4de0993"},"source":["__в) (1 балл)__  Допишите `LMO` для класса `L1Ball`."]},{"cell_type":"code","execution_count":null,"id":"f096cda6","metadata":{"id":"f096cda6"},"outputs":[],"source":["class L1Ball():\n","    \"\"\"\n","    Ограничения — L1 шар.\n","    \"\"\"\n","    def __init__(self, l2_diameter):\n","        self._R = l2_diameter / 2\n","\n","    @torch.no_grad()\n","    def lmo(self, x):\n","        \"\"\"\n","        LMO.\n","\n","        Параметры:\n","            x (torch.Tensor): Градиент в текущей точке\n","\n","        Возвращает:\n","            lmo_solution (torch.Tensor): LMO\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","\n","        return lmo_solution\n","\n","    @torch.no_grad()\n","    def shift_inside(self, x):\n","        \"\"\"\n","        Масштабирование.\n","        \"\"\"\n","        x_norm = torch.norm(x, p=1)\n","        return self._R * x.div(x_norm) if x_norm > self._R else x"]},{"cell_type":"markdown","id":"79105bfd","metadata":{"id":"79105bfd"},"source":["Ниже представлены вспомогательные функции, которые потребуются для инициализации модели."]},{"cell_type":"code","execution_count":null,"id":"cd2a92fc","metadata":{"id":"cd2a92fc"},"outputs":[],"source":["@torch.no_grad()\n","def get_avg_init_norm(layer, param_type=None, repetitions=100):\n","    \"\"\"\n","    Вычисляет среднюю норму инициализации слоя по умолчанию\n","    \"\"\"\n","    output = 0\n","    for _ in range(repetitions):\n","        layer.reset_parameters()\n","        output += torch.norm(getattr(layer, param_type), p=2).item()\n","    return float(output) / repetitions\n","\n","@torch.no_grad()\n","def get_model_init_norms(moduleList):\n","    \"\"\"\n","    Вычисляет среднюю норму инициализации всех слоев по умолчанию\n","    \"\"\"\n","    init_norms = dict()\n","    for module, param_type in moduleList:\n","        if hasattr(module, 'reset_parameters'):\n","            param = getattr(module, param_type)\n","            avg_norm = get_avg_init_norm(module, param_type=param_type)\n","            init_norms[param.shape] = avg_norm\n","    return init_norms\n","\n","@torch.no_grad()\n","def set_constraints(moduleList, setLMO=L1Ball, value=300):\n","    \"\"\"\n","    Создаются ограничения L_1 шара для каждого слоя\n","    \"\"\"\n","    constraintList = []\n","    init_norms = get_model_init_norms(moduleList)\n","    for module, param_type in moduleList:\n","        param = getattr(module, param_type)\n","        diameter = 2.0 * value * init_norms[param.shape]\n","        constraint = setLMO(diameter)\n","        constraintList.append((constraint, param))\n","    return constraintList\n","\n","@torch.no_grad()\n","def make_feasible(constraintList):\n","    \"\"\"\n","    Масштабирование.\n","    \"\"\"\n","    for constraint, param in constraintList:\n","        feasible = constraint.shift_inside(param)\n","        param.copy_(feasible)"]},{"cell_type":"markdown","id":"bfe01db0","metadata":{"id":"bfe01db0"},"source":["__г) (2 балла)__ Реализуйте оптимизатор `SFW`."]},{"cell_type":"code","execution_count":null,"id":"eeacc954","metadata":{"id":"eeacc954"},"outputs":[],"source":["class SFW(optim.Optimizer):\n","    \"\"\"\n","    Реализация стохастического Франк—Вульфа\n","\n","    Параметры:\n","        params (Iterable): Итерируемый объект параметров для оптимизации или словарь\n","        lr (float): Скорость обучения\n","        momentum (float): Коэффициент моментума\n","    \"\"\"\n","\n","    def __init__(self, params, lr=0.9, momentum=0.8):\n","\n","        defaults = dict(lr=lr, momentum=momentum)\n","        super(SFW, self).__init__(params, defaults)\n","\n","    @torch.no_grad()\n","    def step(self, closure=None):\n","        \"\"\"\n","        Выполняет один шаг оптимизатора.\n","\n","        Параметры:\n","            closure (Сallable): Замыкание, которое пересчитывает модель и возвращает loss\n","\n","        Возвращает:\n","            loss (float): Значение функции потерь\n","        \"\"\"\n","\n","        loss = closure() if closure is not None else None\n","\n","        for group in self.param_groups:\n","            lr = group['lr']\n","            momentum = group['momentum']\n","            constraint = group['constraint']\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","\n","                # YOUR CODE HERE\n","\n","        return loss"]},{"cell_type":"markdown","id":"1505f63f","metadata":{"id":"1505f63f"},"source":["__д) (3 балла)__ Запустите обучение ResNet18 на CIFAR10. Подберите гиперпараметры. Радиус для $L_1$ и ядерного шаров должен быть не больше 50."]},{"cell_type":"code","execution_count":null,"id":"792fa32c","metadata":{"id":"792fa32c"},"outputs":[],"source":["class CIFAR10(Dataset):\n","    def __init__(self, root='.', download=True):\n","        transform_train = transforms.Compose([\n","            transforms.RandomCrop(32, padding=4),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","        ])\n","\n","        transform_test = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","        ])\n","\n","        self.train_dataset = torchvision.datasets.CIFAR10(\n","            root = root,\n","            train = True,\n","            transform = transform_train,\n","            download = download,\n","        )\n","        self.test_dataset = torchvision.datasets.CIFAR10(\n","            root = root,\n","            train = False,\n","            transform = transform_test,\n","            download = download,\n","        )"]},{"cell_type":"code","execution_count":null,"id":"50b2724f","metadata":{"id":"50b2724f"},"outputs":[],"source":["CIFAR10_dataset = CIFAR10(root='.')"]},{"cell_type":"code","execution_count":null,"id":"3496b5ed","metadata":{"id":"3496b5ed"},"outputs":[],"source":["def trainer(num_epochs, batch_size, model_class, criterion, optimizer_class=SFW, optimizer_params=None,\n","            constraintList=None, dataset=None, device='cuda' if torch.cuda.is_available() else 'cpu'\n","           ):\n","    \"\"\"\n","    Универсальная функция для обучения моделей PyTorch.\n","\n","    Параметры:\n","        num_epochs (int): Количество эпох обучения\n","        batch_size (int): Размер батча для DataLoader\n","        model_class (nn.Module): Класс модели\n","        criterion (nn.Module): Функция потерь\n","        optimizer_class (optim.Optimizer): Класс оптимизатора\n","        optimizer_params (dict): Параметры оптимизатора\n","        scheduler_class (optim.lr_scheduler): Класс планировщика скорости обучения\n","        constraintList (list): Список ограничений\n","        dataset (Dataset): Объект датасета\n","        device (str): Устройство для вычислений\n","\n","    Возвращает:\n","        model (nn.Module): Обученная модель\n","        metrics (dict): Словарь с логами\n","    \"\"\"\n","\n","    # Создаем загрузчики данных\n","    train_loader = DataLoader(dataset.train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(dataset.test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    model = model_class.to(device)\n","\n","    make_feasible(constraintList)\n","    param_groups = []\n","    for constraint, param_list in constraintList:\n","        param_group = {'params': param_list, 'constraint': constraint}\n","        if optimizer_params:\n","             param_group.update(optimizer_params)\n","        param_groups.append(param_group)\n","    optimizer = optimizer_class(param_groups)\n","\n","    metrics = {\n","        \"train_loss\": [],\n","        \"train_acc\": [],\n","        \"test_loss\": [],\n","        \"test_acc\": [],\n","    }\n","\n","    def train_epoch():\n","        model.train()\n","\n","        # YOUR CODE HERE\n","\n","        return train_loss, train_acc\n","\n","    def test_epoch():\n","        model.eval()\n","\n","        # YOUR CODE HERE\n","\n","        return test_loss, test_acc\n","\n","    for epoch in range(num_epochs):\n","        start = time.time()\n","\n","        train_loss, train_acc = train_epoch()\n","        test_loss, test_acc = test_epoch()\n","\n","        # Сохраняем метрики\n","        metrics[\"train_loss\"].append(train_loss)\n","        metrics[\"train_acc\"].append(train_acc)\n","        metrics[\"test_loss\"].append(test_loss)\n","        metrics[\"test_acc\"].append(test_acc)\n","\n","        elapsed = time.time() - start\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n","              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | \"\n","              f\"Test Loss: {test_loss:.4f}, Acc: {test_acc:.2f}% | \"\n","              f\"Time: {elapsed:.2f}s\")\n","    return model, metrics"]},{"cell_type":"markdown","id":"d9fa50b0","metadata":{"id":"d9fa50b0"},"source":["Наложение ограничений только на сверточные и линейные слои."]},{"cell_type":"code","execution_count":null,"id":"9046189b","metadata":{"id":"9046189b"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"id":"1562ced8","metadata":{"id":"1562ced8"},"outputs":[],"source":["model_sfw_nuclear = resnet18(weights=None, num_classes=10)\n","\n","moduleList_nuclear = []\n","for name, module in model_sfw_nuclear.named_modules():\n","    if isinstance(module, (nn.Conv2d, nn.Linear)):\n","        moduleList_nuclear.append((module, 'weight'))\n","\n","constraints_nuclear = set_constraints(moduleList=moduleList_nuclear, value=40.0, setLMO=NuclearNormBall)\n","\n","config_sfw_nuclear = {\n","    'num_epochs': ...,\n","    'batch_size': ...,\n","    'model_class': resnet18(weights=None, num_classes=10),\n","    'criterion': nn.CrossEntropyLoss(reduction='mean'),\n","    'optimizer_class': SFW,\n","    'optimizer_params': {\n","        'lr': ...,\n","        'momentum': ...,\n","    },\n","    'constraintList': constraints_nuclear,\n","    'dataset': CIFAR10_dataset,\n","    'device': device,\n","}\n","\n","print(\"Обучение ResNet18 с помощью SFW на ядерном шаре\")\n","trained_model_sfw_nuclear, metrics_sfw_nuclear = trainer(**config_sfw_nuclear)"]},{"cell_type":"code","execution_count":null,"id":"03898cf5","metadata":{"id":"03898cf5"},"outputs":[],"source":["model_sfw_l1 = resnet18(weights=None, num_classes=10)\n","\n","moduleList_l1 = []\n","for name, module in model_sfw_l1.named_modules():\n","    if isinstance(module, (nn.Conv2d, nn.Linear)):\n","        moduleList_l1.append((module, 'weight'))\n","\n","constraints_l1 = set_constraints(moduleList=moduleList_l1, value=50.0, setLMO=L1Ball)\n","\n","config_sfw_l1 = {\n","    'num_epochs': ...,\n","    'batch_size': ...,\n","    'model_class': model_sfw_l1,\n","    'criterion': nn.CrossEntropyLoss(reduction='mean'),\n","    'optimizer_class': SFW,\n","    'optimizer_params': {\n","        'lr': ...,\n","        'momentum': ...,\n","    },\n","    'constraintList': constraints_l1,\n","    'dataset': CIFAR10_dataset,\n","    'device': device,\n","}\n","\n","print(\"Обучение ResNet18 с помощью SFW на L1 шаре\")\n","trained_model_sfw_l1, metrics_sfw_l1 = trainer(**config_sfw_l1)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}